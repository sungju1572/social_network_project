colors <- ifelse(my_ray4>=10,"red",
ifelse(my_ray4>=6,"yellow","green"))
colors
colors <- ifelse(my_ray4>=10,"red",my_ray4)
colors
colors <- ifelse(my_ray4>=10,"red",ifelse(my_ray4>=6,"yellow","green"))
colors
ctable <- data.frame(x=c("3","7","9","10"),
y=c("A1","B2","A1","B2"),
num=c(4,6,2,9))
xtabs(num~x,Ctable)
xtabs(num~x,data=ctable)
xtabs(num~y,ctable)
## 시계열 분석
install.packages("tseries")
## 시계열 분석
library(tseries)
install.packages("forecast")
install.packages("TTR")
install.packages("TTR")
## 시계열 분석
library(tseries)
library(forecast)
library(TTR)
library(dplyr)
library(tidyverse)
library(data.table)
library(ROCR)
king <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
king
king.ts <- ts(king)
king.ts
plot.ts(king.ts)
## 3년마다 평균을 내서 그래프를 부드럽게 표현
king.sma3 <- SMA(king.ts,n=3)
plot.ts(king.sma3)
## 8년
king.sma8 <- SMA(king.ts,n=8)
plot.ts(king.sma8)
## ARIMA모델
king.ff1 <- diff(king.ts,differences=1)
plot.ts(king.ff1)
## ACF와 PACF를 통한 적합한 ARIMA모델 결정
acf(king.ff1,lag.max=20)
acf(king.ff1,lag.max=20,plot=FALSE)
pacf(king.ff1, lag.max=20)
pacf(king.ff1, lag.max=20, plot+FALSE)
pacf(king.ff1, lag.max=20, plot=FALSE)
auto.arima(king)
king.arima <- (king,order=c(0,1,1))
king.arima <-arima(king,order=c(0,1,1))
king.forecasts <- forecast(king.arima)
king.forecasts
####다차원척도법####
library(MASS)
loc <- cmdscale(eurodist)
x <- loc[,1]
loc <- cmdscale(eurodist)
x <- loc[,1]
y <- -loc[,2]
loc
plot(x,y,type="n", asp=1, main="Metric MDS")
plot(x,y,type="n",main="Metric MDS")
plot(x,y,type="n", asp=1, main="Metric MDS")
plot(x,y,type="n",main="Metric MDS")
plot(x,y,type="n", asp=1, main="Metric MDS")
plot(x,y,type="n", asp=2, main="Metric MDS")
plot(x,y,type="n", asp=1, main="Metric MDS")
text(x,y,rownames(loc),cex=0.7)
abline(v=0,h=0,lty=2,lwd=0.5)
## 비계량적MDS
data(swiss)
swiss.x <- as.matrix(swiss[,-1])
swiss.dist <- dist(swiss.x)
swiss.mds <- isoMDS(swiss.dist)
plot(swiss.mds$points,type="n")
text(swiss.mds$points,labels=as.character(1:nrow(swiss.x)))
abline(v=0,h=0,lty=2,lwd=0.5)
(swiss.x <- as.matrix(swiss[,-1]))
swiss
(swiss.dist <- dist(swiss.x))
(swiss.mds <- isoMDS(swiss.dist))
?dist
swiss.x <- as.matrix(swiss[,-1])
(swiss.x <- as.matrix(swiss[,-1]))
(swiss.sammon <- sammon(dist(swiss.x)))
plot(swiss.sammon$points,type="n")
text(swiss.sammon$points,labels=as.character(1:nrow(swiss.x)))
abline(v=0,h=0,lty=2,lwd=0.5)
## 주성분 분석
library(datasets)
data("USArrests")
pairs(USArrests,panel=panel.smooth, main="USArrests data")
US.prin <- princomp(USArrest,cor+TURE)
US.prin <- princomp(USArrests,cor+TURE)
US.prin <- princomp(USArrests,cor=TURE)
US.prin <- princomp(USArrests,cor=TRUE)
summary(US.prin)
screeplot(US.prin,npcs=4,type="lines")
screeplot(US.prin,npcs=10,type="lines") ## summary
screeplot(US.prin,npcs=4,type="lines") ## summary
US.prin
loadings(US.prin)
US.prin$scores
arrest.pca <- prcomp(USArrests,center=TRUE, scale.=TRUE)
biplot(arrests.pca,scale=0)
arrests.pca <- prcomp(USArrests,center=TRUE, scale.=TRUE)
biplot(arrests.pca,scale=0)
rm(arrest.pca)
loadings(US.prin) ## 기여도 확인
screeplot(US.prin,npcs=4,type="lines") ## summary
summary(US.prin) ##요약치 확인
library(tibble)
raw <- tibble(cusid=c("c01","c02","c03","c04","c05"),
gender=c(2,1,1,2,1),
wk1=c(4,NA,15,3,6),
wk2=c(NA,NA,8,15,22),
wk3=c(11,2,14,23,NA),
wk4=c(19,25,28,13,6),
wk5=c(22,18,NA,19,14),
wk6=c(5,13,NA,7,NA),
wk7=c(12,8,NA,10,30))
raw
str(raw)
summary(raw)
library(tidyr)
raw_long <- gather(data=raw,
key=week,value=result,
wk1,wk2,wk3,wk4,wk5,wk6,wk7)
raw_long
str(raw_long)
library(magrittr);library(dplyr)
raw_long %<>% arrange(cusid)
raw_long
library(doBy)
raw_long$week %<>% recodeVar(src=c("wk1","wk2","wk3","wk4","wk5","wk6","wk7"),
tgt=c(1,2,3,4,5,6,7))
raw_long
str(raw_long)
raw_long
library(tidyr)
raw_wide <- spread(data=raw_long,
key=week,value=result)
raw_wide
str(raw_wide)
raw_wide%<>%dplyr::rename(wk1="1",wk2="2",wk3="3",wk4="4",wk5="5",wk6="6",wk7="7")
raw_wide
str(raw_wide)
identical(raw,raw_wide)
raw
raw_long
raw_final <- raw_long %>% group_by(cusid) %>%
dplyr::summarize(result_n=sum(!is.na(result)),
result_sum=sum(result,na.rm=TRUE),
result_avg=mean(result,na.rm=TRUE),
result_median=median(result,na.rm=TRUE),
result_sd=sd(result,na.rm=TRUE),
result_min=min(result,na.rm=TRUE),
result_max=max(result,na.rm=TRUE))
raw_final
raw_final %>%
arrange(desc(result_sum),
desc(result_avg),
result_sd)
sample(1,1000,replace=TRUE,prob=c(0.7,0.3))
sample(2,1000,replace=TRUE,prob=c(0.7,0.3))
sample(1000,100)
table(sample(2,1000,replace=TRUE,prob=c(0.7,0.3)))
table(sample(2,1000,replace=TRUE,prob=c(0.7,0.3))==2)
table(sample(2,1000,replace=TRUE,prob=c(0.7,0.3))==1)
"*"(2,3)
z <- c(1,2,3,4,NA)
summary(z)
a <- 1:100
sum(a>50)
a>50
dfx <- data.frame(
group = c(rep('A', 8), rep('B', 15), rep('C', 6)),
sex = sample(c("M", "F"), size = 29, replace = TRUE),
age = runif(n = 29, min = 18, max = 54)
)
dfx
ddply(dfx, .(group, sex), summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
library(dplyr)
ddply(dfx, .(group, sex), summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
library(data.table)
library(tidyverse)
ddply(dfx, .(group, sex), summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
library(plyr)
ddply(dfx, .(group, sex), summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
ddply(dfx, ~group+sex, summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
dfx <- data.frame(
group = c(rep('A', 8), rep('B', 15), rep('C', 6)),
sex = sample(c("M", "F"), size = 29, replace = TRUE),
age = runif(n = 29, min = 18, max = 54)
)
dfx
ddply(dfx, age~group+sex, summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
ddply(dfx, age~group, summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
ddply(dfx, group~sex, summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
ddply(dfx, ~group+sex, summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
ddply(dfx, group+sex~, summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
ddply(dfx, group+sex~., summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
ddply(dfx, cbind(group,sex)~, summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
2^3
2**3
2^12.2
2**12.2
3.535e-05
3.535e-05 %>% as.numeric()
as.numeric(3.535e-05)
options(scipen=999)
3.535e-05
## ROC 커브 ##
library(caret)
library(ROCR)
data(ROCR.simple)
pred <- prediction(ROCR.simple$predictions,ROCR.simple$labels)
pref <- performance(pred,measure = "tpr",x.measure = "fpr")
pref.auc <- performance(pred,measure="auc")
pref.auc@y.values ## auc 확인
plot(pref,main="ROC curve",col="blue","lwd=2")
pred
summary(pred)
pred <- prediction(ROCR.simple$predictions,ROCR.simple$labels)
pref <- performance(pred,measure = "tpr",x.measure = "fpr")
pref
inspect(pref)
summary(pref)
pref <- performance(pred,measure = "tpr",x.measure = "fpr")
plot(pref)
plot(pref,main="ROC curve",col="blue",lwd='2")
my_pred <- prediction(pred,auc_test_voted)
plot(performance(my_pred,"tpr","fpr"))
slot(performance(my_pred,"auc"),"y.values")
#### 모델성능 향상 ####
## 난수 이용 ##
random_ids <- order(runif(1000)) ## 0~1 사이의 난수 생성--> 난수의 순서를 정수로
credit_train <- credit[random_ids[1:500],]
credit_validate <- credit[random_ids[501:750],]
credit_test <- credit[random_ids[751:1000],]
## caret 패키지 ##
in_train <- createDataPartition(credit$default, p=0.75, list=FALSE)
credit_train <- credit[in_train,]
credit_test <- credit[-in_train,]
## 반복 홀드아웃 ##
fold <- createFolds(credit$default,k=10)
credit01_test <- credit[folds$Fold01,]
credit01_train <- credit[-fold$Fold01,]
library(C50)
cv_result <- lapply(folds,function(x){
credit_train <- credit[-x,]
credit_test <- credit[x,]
credit_model <- C5.0(default~.,data=credit_train)
credit_pred <- predict(credit_model,credit_test)
credit_actual <- credit_test$default
rslt <- table(credit_pred,credit_actual)
pr_a <- "TP+TN 값을 더한 값"
pr_e <- "예측P*실제P+예측N*실제N"
kappa <- (pr_a-pr_e)/(1-pr_e)
})
#### 메타학습 ####
## 배깅 ##
library(ipred)
set.seed(300)
mybag <- bagging(default~.,data=credit_train,nbagg=25)
credit_pred <- predict(mybag,credit_train)
table(credit_pred,credit_train$default) ## 학습결과 확인
credit_pred2 <- predict(mybag,credit_test)
table(credit_pred2,credit_test$default) ## 테스트결과 확인
## caret 패키지 이용 ##
library(caret)
m <- train(default~.,data=credit_train,method="treebag")
table(credit_test$default,predict(m,credit_test))
## 부스팅 ##
library(C50)
m_c50_bst <- C5.0(default~.,data=credit_train,trials=100) ## boost이용
## Ada boost 이용 ##
library(adabag)
m_adaboost <- boosting(default~.,data=credit_train)
p_adaboost <- predict(m_adaboost,credit)
head(p_adaboost$class)
p_adaboost$confusion
plot(pref,main="ROC curve",col="blue",lwd="2")
plot(pref,main="ROC curve",col="blue",lwd="5")
)
))
""
;
''
'
plot(pref,main="ROC curve",col="blue",lwd="5")
plot(pref,main="ROC curve",col="blue",lwd=5)
slot(pref,"y.values")
pref.auc@y.values ## auc 확인
#### 문자열 처리 ####
library(stringr)
## 문자열 찾기 ##
fruits <- c("apple","Apple","banana","pineapple")
str_detect(fruits,"A") ## A가 있는 단어 찾기
str_detect(fruits,"^a") ## a로 시작하는 단어 찾기
str_detect(fruits,"e$") ## e로 끝나는 단어 찾기
str_detect(fruits,"^[aA]") ## 시작하는 글자가 a 또는 A인 단어찾기
str_detect(fruits,"[aA]") ## a 또는 A가 들어간 단어 찾기
## regex ##(패턴 찾기)
str_detect(fruits,regex('a',ignore_case = T)) ## a든A든 상관없이 찾기
str_detect(fruits,"(?i)a") ## 정규식으로 같은 결과
str_detect(fruits,"(i)a") ## 정규식으로 같은 결과
str_detect(fruits,"(?i)a") ## 정규식으로 같은 결과
str_locate(fruits,"a")
#### 문자열 처리 ####
library(stringr)
## 문자열 찾기 ##
fruits <- c("apple","Apple","banana","pineapple")
## 특정 문자 위치 찾기 ##
str_locate("apple","a")
str_locate(fruits,"(?i)a")
str_locate(fruits,"a")
str_locate_all(fruits,"a")
44%/%12
44%%12
23%%12
88%%12
94%%12
39%%12
12%%12
44%%8
13%%12
88%%12
23%%12
94%%12
11%%12
39%%12
20%%12
16%%12
44%%12
44 %% 11
13 %%11
88%%11
23%%11
94%%11
39%%11
39%%6
39%%11
12%%11
44%%0
12%%11
44%%11
13%%11
88%%11
23%%11
94%%11
11%%11
39%%11
20%%11
16%%11
9!
9*8*7*6*5*4*3*2
distance(1,10,)
dist(c(1,10),c(5,19))
dist <- data.frame(x=c(1,5,20,7,9,8,16,22,7),
y=c(10,19,2,5,14,10,12,5,12))
dist(dist)
sort(c(-10,5,3,2))
sort(c(-10,-5,-3,-2))
a <-prod(1:9)
a
b <- 2**5 *3
b
a/b
a <- prod(1:9)
x <- 3^5 * 4
a/x
x <- 3^3 *4
x
a/x
(99/100)*100-1
(99/100)*100
1-(99/100)
1-(99/100)^^100
1-(99/100)**100
## 과제 ##
library(TSA)
library(forecast)
data("beersales")
data("wineind")
help("beersales")
install.packages("pracmat")
가나다
한글 잘 쳐지나요
install.packages("wavScalogram")
#### 웨이블릿 변환 ####
library(wavScalogram)
dt <- 0.1
time <- seq(0,50,dt)
signal <- c(sin(pi*time),sin(pi*time/2))
plot(1:length(signal),signal,"l")
rslt1 <-scalogram(signal,dt=1)
order(rslt1$scalog,decreasing = TRUE)
which(order(rslt1$scalog,decreasing=TRUE)<=10)
cwt <- cwt_wst(signal=signal,dt=dt,energy_density = TRUE)
install.packages("shiny")
library(shiny)
ui <- fluidPage("")
ui <- fluidPage(
"Hello, Data Science!"
)
server <- function(input,output,session){}
shinyApp(ui=ui,server=server)
#### 웹 크롤링 ####
res <- GET(url="https://section.blog.naver.com/BlogHome.nhn?",
query=list(directoryNo=0,
currentPage=1,
groupld=0))
?GET
??GET
library(httr)
install.packages("httr")
install.packages("httr")
#### 웹 크롤링 ####
librar(httr)
#### 웹 크롤링 ####
library(httr)
res <- GET(url="https://section.blog.naver.com/BlogHome.nhn?",
query=list(directoryNo=0,
currentPage=1,
groupld=0))
res
print(x=res)
status_code(x=res)
content(x=res,as="text",type="text/html",encoding="EUC-KR")
res <- GET(url="https://www.naver.com")
print(x=res)
status_code(x=res)
content(x=res,as="text",encoding="UTF-8")
load("C:/Users/LeeGeon.DESKTOP-C5M3NRB.000/Documents/R_data/.RData")
rm(list=ls())
setwd('C:\\Users\\LeeGeon.DESKTOP-C5M3NRB.000\\Documents\\GitHub\\social_network_project\\LeeGeon\\OP_GG_Data')
library(httr)
library(rvest)
library(urltools)
library(readr)
library(tidyverse)
#---------------
Champion_total <- read.csv("Champion_name.csv") # 앞서 저장한 OPGG_Champion_name.csv 파일 불러오기
My_Champion <- Champion_total[53:104,] # 내 담당부분(블리츠-일라오이)만 꺼낸다
My_Champion <- My_Champion[-which(My_Champion$Korean_Champ=="스카너"),]
url <- character()
for(x in 1:nrow(My_Champion)){ # 라인에 값이 있으면(그 라인 데이터가 존재함) position 데이터프레임에 추가
position=data.frame()
if(My_Champion[x,3]==1){
position=rbind(position,data.frame(Line="top"))
}
if(My_Champion[x,4]==1){
position=rbind(position,data.frame(Line="jungle"))
}
if(My_Champion[x,5]==1){
position=rbind(position,data.frame(Line="mid"))
}
if(My_Champion[x,6]==1){
position=rbind(position,data.frame(Line="bot"))
}
if(My_Champion[x,7]==1){
position=rbind(position,data.frame(Line="support"))
}
url <- rbind(url,data.frame(url=paste0("https://www.op.gg/champion/",My_Champion$search[x],"/statistics/",position$Line,"/matchup")))
# position을 이용해 https://www.op.gg/champion/챔피언/statistics/position/matchup을 완성시킨다(사용할 Url)
}
ChampionTierlist <- data.frame() # 각 챔피언-라인별 티어를 구하기 위한 데이터프레임
for(x in 1:nrow(url)){
res <- GET(url=url[x,])
Tier <- res %>% read_html() %>%
html_nodes(css='div.champion-stats-header-info__tier > b') %>% html_text() %>% str_sub(start=-1) %>% as.integer()
ChampionTierlist <- rbind(ChampionTierlist,data.frame(Line=str_sub(url[x,],start=url[x,] %>% str_locate_all('/statistics/') %>% unlist() %>% .[[2]]+1,
end=url[x,] %>% str_locate_all('/matchup') %>% unlist() %>%.[[1]]-1),
Champion=str_sub(url[x,],start=url[x,] %>% str_locate_all('/champion/') %>% unlist() %>% .[[2]]+1,
end=url[x,] %>% str_locate_all('/statistics/') %>% unlist() %>%.[[1]]-1),
Tier=Tier))
}
ChampionTierlist$Line <- as.character(factor(ChampionTierlist$Line,
levels=c("top","jungle","mid","bot","support"),
labels=c("Top","Jungle","Middle","Bottom","Support")))
for(x in 1:nrow(ChampionTierlist)){
My_Champion[which(My_Champion$search %in% ChampionTierlist$Champion[x]),
which(colnames(My_Champion) %in% ChampionTierlist$Line[x])] <- ChampionTierlist$Tier[x]
}
My_Champion %>% View()
write.csv(My_Champion,"ChampionTierList(Blitz-Illa).csv",row.names=FALSE)
